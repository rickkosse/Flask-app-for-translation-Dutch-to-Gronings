import pickle

param = {'FORCE_RELOAD_VOCABULARY': False, 'TRAIN_ON_TRAINVAL': False, 'MODE': 'training', 'REBUILD_DATASET': True, 'RELOAD_EPOCH': True, 'RELOAD': 0, 'VERBOSE': 1, 'PLOT_EVALUATION': False, 'SAMPLING_SAVE_MODE': 'list', 'WORD_EMBEDDINGS_LABELS': ['source_text', 'target_text'], 'LABEL_WORD_EMBEDDINGS_WITH_VOCAB': True, 'EMBEDDINGS_METADATA': None, 'EMBEDDINGS_LAYER_NAMES': ['source_word_embedding', 'target_word_embedding'], 'EMBEDDINGS_FREQ': 1, 'LOG_DIR': 'tensorboard_logs', 'TENSORBOARD': True, 'DATASET_STORE_PATH': 'datasets/bpe/', 'STORE_PATH': 'trained_models_bpe/EuTrans_nlgro_AttentionRNNEncoderDecoder_src_emb_32_bidir_True_enc_LSTM_32_dec_ConditionalLSTM_32_deepout_linear_trg_emb_32_Adam_0.001/', 'MODEL_NAME': 'EuTrans_nlgro_AttentionRNNEncoderDecoder_src_emb_32_bidir_True_enc_LSTM_32_dec_ConditionalLSTM_32_deepout_linear_trg_emb_32_Adam_0.001', 'EXTRA_NAME': '', 'DOUBLE_STOCHASTIC_ATTENTION_REG': 0.0, 'USE_L2': False, 'USE_L1': False, 'USE_PRELU': False, 'BATCH_NORMALIZATION_MODE': 1, 'USE_BATCH_NORMALIZATION': False, 'NOISE_AMOUNT': 0.01, 'USE_NOISE': False, 'ATTENTION_DROPOUT_P': 0.0, 'RECURRENT_DROPOUT_P': 0.0, 'RECURRENT_INPUT_DROPOUT_P': 0.0, 'DROPOUT_P': 0.0, 'RECURRENT_WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY': 0.0001, 'REGULARIZATION_FN': 'L2', 'N_HEADS': 8, 'FF_SIZE': 128, 'MULTIHEAD_ATTENTION_ACTIVATION': 'linear', 'MODEL_SIZE': 32, 'SKIP_VECTORS_SHARED_ACTIVATION': 'tanh', 'ADDITIONAL_OUTPUT_MERGE_MODE': 'Add', 'SKIP_VECTORS_HIDDEN_SIZE': 32, 'ATTENTION_SIZE': 32, 'DECODER_HIDDEN_SIZE': 32, 'INIT_LAYERS': ['tanh'], 'BIDIRECTIONAL_MERGE_MODE': 'concat', 'BIDIRECTIONAL_DEEP_ENCODER': True, 'BIDIRECTIONAL_ENCODER': True, 'ENCODER_HIDDEN_SIZE': 32, 'ATTENTION_MODE': 'add', 'DECODER_RNN_TYPE': 'ConditionalLSTM', 'USE_CUDNN': False, 'ENCODER_RNN_TYPE': 'LSTM', 'DEEP_OUTPUT_LAYERS': [('linear', 32)], 'N_LAYERS_DECODER': 1, 'N_LAYERS_ENCODER': 1, 'TIE_EMBEDDINGS': False, 'SCALE_TARGET_WORD_EMBEDDINGS': False, 'SCALE_SOURCE_WORD_EMBEDDINGS': False, 'TRG_PRETRAINED_VECTORS_TRAINABLE': True, 'TRG_PRETRAINED_VECTORS': None, 'TARGET_TEXT_EMBEDDING_SIZE': 32, 'SRC_PRETRAINED_VECTORS_TRAINABLE': True, 'SRC_PRETRAINED_VECTORS': None, 'SOURCE_TEXT_EMBEDDING_SIZE': 32, 'INIT_ATT': 'glorot_uniform', 'INNER_INIT': 'orthogonal', 'INIT_FUNCTION': 'glorot_uniform', 'TRAINABLE_DECODER': True, 'TRAINABLE_ENCODER': True, 'MODEL_TYPE': 'AttentionRNNEncoderDecoder', 'STOP_METRIC': 'Bleu_4', 'PATIENCE': 15, 'EARLY_STOP': True, 'SAVE_EACH_EVALUATION': True, 'WRITE_VALID_SAMPLES': True, 'EPOCHS_FOR_SAVE': 1, 'PARALLEL_LOADERS': 1, 'JOINT_BATCHES': 4, 'HOMOGENEOUS_BATCHES': False, 'N_GPUS': 0, 'BATCH_SIZE': 50, 'MAX_EPOCH': 500, 'MIN_LR': 1e-09, 'WARMUP_EXP': -1.5, 'LR_HALF_LIFE': 100, 'LR_REDUCER_EXP_BASE': -0.5, 'LR_REDUCER_TYPE': 'exponential', 'LR_START_REDUCTION_ON_EPOCH': 0, 'LR_REDUCE_EACH_EPOCHS': False, 'LR_GAMMA': 0.8, 'LR_DECAY': None, 'ACCUMULATE_GRADIENTS': 1, 'EPSILON': 1e-08, 'AMSGRAD': False, 'BETA_2': 0.999, 'BETA_1': 0.9, 'RHO': 0.9, 'NESTEROV_MOMENTUM': False, 'MOMENTUM': 0.0, 'USE_TF_OPTIMIZER': True, 'CLIP_V': 0.0, 'CLIP_C': 5.0, 'LR': 0.001, 'OPTIMIZER': 'Adam', 'LABEL_SMOOTHING': 0.0, 'SAMPLE_WEIGHTS': True, 'CLASSIFIER_ACTIVATION': 'softmax', 'LOSS': 'categorical_crossentropy', 'MAX_OUTPUT_TEXT_LEN_TEST': 900, 'MAX_OUTPUT_TEXT_LEN': 300, 'MIN_OCCURRENCES_OUTPUT_VOCAB': 0, 'OUTPUT_VOCABULARY_SIZE': 0, 'MAX_INPUT_TEXT_LEN': 300, 'MIN_OCCURRENCES_INPUT_VOCAB': 0, 'INPUT_VOCABULARY_SIZE': 0, 'PAD_ON_BATCH': True, 'FILL': 'end', 'DATA_AUGMENTATION': False, 'TOKENIZE_REFERENCES': True, 'TOKENIZE_HYPOTHESES': True, 'APPLY_DETOKENIZATION': False, 'DETOKENIZATION_METHOD': 'detokenize_none', 'BPE_CODES_PATH': 'examples/EuTrans//training_codes.joint', 'TOKENIZATION_METHOD': 'tokenize_none', 'MAPPING': 'examples/EuTrans//mapping.nl_gro.pkl', 'ALIGN_FROM_RAW': True, 'HEURISTIC': 0, 'POS_UNK': True, 'SAMPLE_EACH_UPDATES': 300, 'START_SAMPLING_ON_EPOCH': 1, 'N_SAMPLES': 5, 'SAMPLE_ON_SETS': ['train', 'val'], 'ALPHA_FACTOR': 0.6, 'NORMALIZE_SAMPLING': False, 'COVERAGE_NORM_FACTOR': 0.2, 'COVERAGE_PENALTY': False, 'LENGTH_NORM_FACTOR': 0.2, 'LENGTH_PENALTY': False, 'MINLEN_GIVEN_X_FACTOR': 3, 'MINLEN_GIVEN_X': True, 'MAXLEN_GIVEN_X_FACTOR': 2, 'MAXLEN_GIVEN_X': True, 'SEARCH_PRUNING': False, 'OPTIMIZED_SEARCH': True, 'BEAM_SIZE': 6, 'BEAM_SEARCH': True, 'TEMPERATURE': 1, 'SAMPLING': 'max_likelihood', 'EVAL_EACH': 1, 'EVAL_EACH_EPOCHS': True, 'START_EVAL_ON_EPOCH': 1, 'EVAL_ON_SETS_KERAS': [], 'EVAL_ON_SETS': ['val'], 'METRICS': ['coco'], 'OUTPUTS_TYPES_DATASET': ['text-features'], 'INPUTS_TYPES_DATASET': ['text-features', 'text-features'], 'OUTPUTS_IDS_MODEL': ['target_text'], 'INPUTS_IDS_MODEL': ['source_text', 'state_below'], 'OUTPUTS_IDS_DATASET': ['target_text'], 'INPUTS_IDS_DATASET': ['source_text', 'state_below'], 'GLOSSARY': None, 'TEXT_FILES': {'train': 'training.', 'val': 'dev.', 'test': 'test.'}, 'DATA_ROOT_PATH': 'examples/EuTrans/', 'TRG_LAN': 'gro', 'SRC_LAN': 'nl', 'DATASET_NAME': 'EuTrans', 'TASK_NAME': 'EuTrans'} 

with open('bpe_config.pkl', 'wb') as handle:
    pickle.dump(param, handle, protocol=pickle.HIGHEST_PROTOCOL)
